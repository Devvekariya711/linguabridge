# LinguaBridge ğŸŒ‰

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/FastAPI-0.100+-green?logo=fastapi&logoColor=white" alt="FastAPI">
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License">
  <img src="https://img.shields.io/badge/Platform-Windows%20|%20Linux%20|%20Android-lightgrey" alt="Platform">
  <img src="https://img.shields.io/badge/Offline-100%25-orange" alt="Offline">
</p>

<p align="center">
  <b>Real-time offline voice translation</b> â€” Speak in one language, hear in another. No internet required.
</p>

---

## ğŸ¤” Why LinguaBridge?

- ğŸ’¡ **100% Offline** â€” All AI models run locally on your device
- ğŸ”’ **Privacy First** â€” No data leaves your computer, ever
- ğŸ’¸ **Zero Cost** â€” No API keys, no subscriptions, no cloud fees
- âš¡ **Fast** â€” ~1.2s latency after warmup
- ğŸŒ **Multi-Language** â€” English, Hindi, Japanese support

---

## âœ¨ Features

| Feature | Technology | Status |
|---------|------------|--------|
| ğŸ¤ **Speech-to-Text** | Faster-Whisper (OpenAI Whisper) | âœ… |
| ğŸŒ **Translation** | Argos Translate (Neural MT) | âœ… |
| ğŸ”Š **Text-to-Speech** | Piper TTS (ONNX voices) | âœ… |
| ï¿½ï¸ **Server** | FastAPI + Socket.IO | âœ… |
| ğŸ“± **Mobile App** | Kivy (Python) | âœ… |
| ğŸŒ **Web Frontend** | React (coming soon) | ğŸ”§ |

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/Devvekariya711/linguabridge.git
cd linguabridge
```

### 2. Create virtual environment
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Download AI models
```bash
python backend/download_models.py --all
```

### 5. Start the server
```bash
python -m uvicorn backend.server.server_main:asgi_app --port 8000
```

### 6. Test translation
```bash
python test_quick.py
```

---

## ğŸ“ Project Structure

```
linguabridge/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server/              # FastAPI + Socket.IO server
â”‚   â”‚   â”œâ”€â”€ engine_stt.py        # Whisper STT
â”‚   â”‚   â”œâ”€â”€ engine_nmt.py        # Argos + LLM Translation
â”‚   â”‚   â”œâ”€â”€ engine_tts.py        # Piper TTS
â”‚   â”‚   â”œâ”€â”€ engine_llm.py        # Ollama LLM wrapper
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # Sentence-transformers
â”‚   â”‚   â”œâ”€â”€ vector_db.py         # ChromaDB vector store
â”‚   â”‚   â”œâ”€â”€ translation_memory.py # SQLite + RAG cache
â”‚   â”‚   â””â”€â”€ server_main.py       # Main server
â”‚   â”œâ”€â”€ app/                 # Kivy mobile app
â”‚   â”‚   â”œâ”€â”€ main.py              # App entry
â”‚   â”‚   â””â”€â”€ audio_streamer.py    # Mic capture
â”‚   â””â”€â”€ database/            # SQLite + ChromaDB storage
â”œâ”€â”€ frontend/                # React web UI (coming)
â”œâ”€â”€ git/                     # CI/CD, scripts, docs
â”‚   â”œâ”€â”€ .github/workflows/       # GitHub Actions
â”‚   â””â”€â”€ scripts/                 # Build scripts
â””â”€â”€ requirements.txt         # All dependencies
```

---

## ğŸŒ Supported Languages

| Language | STT | Translation | TTS |
|----------|:---:|:-----------:|:---:|
| English | âœ… | âœ… | âœ… |
| Hindi | âœ… | âœ… | âœ… |
| Japanese | âœ… | âœ… | âŒ |

---

## âš¡ Performance

| Metric | Cold Start | Warm | With Cache |
|--------|-----------|------|------------|
| **Full Pipeline** | ~9s | ~1.2s | **<0.1s** |
| STT (3s audio) | ~5s | ~0.6s | - |
| Translation (LLM) | ~3s | ~2s | **<1ms** |
| Translation (Argos) | ~0.5s | ~0.2s | **<1ms** |
| TTS | ~2.5s | ~0.3s | - |

> ğŸ’¡ **Translation Memory:** Cached phrases return in <1ms via exact match or vector search.

---

## ğŸ”§ API Reference

### REST Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/ping` | GET | Health check |
| `/api/status` | GET | Engine status |

### Socket.IO Events

```javascript
// Transcribe voice
socket.emit('voice_chunk', audioBlob);
socket.on('transcription_result', (data) => console.log(data.text));

// Translate text
socket.emit('translate_text', {
  text: 'Hello',
  source_lang: 'en',
  target_lang: 'hi'
});
socket.on('translation_result', (data) => console.log(data.translated));

// Full pipeline (STT â†’ NMT â†’ TTS)
socket.emit('full_pipeline', {
  audio: audioBlob,
  source_lang: 'en',
  target_lang: 'hi'
});
socket.on('pipeline_result', (data) => {
  console.log(data.original, 'â†’', data.translated);
  playAudio(data.audio);
});
```

---

## ğŸ› ï¸ Development

```bash
# Run interactive test
python test_quick.py

# Run full pipeline test
python test_pipeline.py

# Run latency benchmark
python benchmark_latency.py
```

---

## ğŸ“‹ Requirements

- Python 3.10+
- ~3GB disk space for AI models
- ~90MB for embedding model
- Microphone (for voice input)
- Speakers (for audio output)
- **Optional:** Ollama for LLM translation
- **Optional:** GPU for faster inference

---

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ”’ Security

See [SECURITY.md](SECURITY.md) for security policy and responsible disclosure.

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Credits

| Component | Technology |
|-----------|------------|
| STT | [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) |
| Translation | [Argos Translate](https://github.com/argosopentech/argos-translate) |
| LLM | [Ollama](https://ollama.ai) |
| Vector Search | [ChromaDB](https://github.com/chroma-core/chroma) |
| Embeddings | [Sentence-Transformers](https://www.sbert.net/) |
| TTS | [Piper TTS](https://github.com/rhasspy/piper) |
| Server | [FastAPI](https://fastapi.tiangolo.com/) |
| Mobile UI | [Kivy](https://kivy.org/) |

---

<p align="center">
  Made with â¤ï¸ by <a href="https://github.com/Devvekariya711">Dev Vekariya</a>
</p>

<p align="center">
  â­ Star this repo if you find it useful!
</p>
